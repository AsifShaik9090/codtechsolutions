{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/9FAtxCqwp23dbIO9OXa+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsifShaik9090/codtechsolutions/blob/main/codtechitsolutions1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CODTECH IT SOLUTIONS**\n",
        "# *1. Simple Text Classification:*"
      ],
      "metadata": {
        "id": "OfusyvMFEgN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "!pip install nltk\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define the text snippets and the categories\n",
        "texts = [\"I THINK EVERYONE HATES ME ON HERE lol\",\"soooooo wish i could, but im in school and myspace is completely blocked\",\"My bike was put on hold...should have known that.... argh total bummer\",\"you guys didn`t say hi or answer my questions yesterday but nice songs\"]\n",
        "categories = [\"positive\", \"negative\", \"neutral\", \"negative\", \"positive\"]\n",
        "print(f\"Number of text snippets: {len(texts)}\")\n",
        "print(f\"Number of categories: {len(categories)}\")\n",
        "for i, text in enumerate(texts):\n",
        "    print(f\"Text {i+1}: {text}\")\n",
        "    print(f\"Category {i+1}: {categories[i]}\")\n",
        "    print(f\"Length of texts: {len(texts)}\")\n",
        "print(f\"Length of categories: {len(categories)}\")\n",
        "\n",
        "# Pre-process the text snippets\n",
        "# Convert to lowercase\n",
        "texts = [text.lower() for text in texts]\n",
        "# Remove punctuation\n",
        "texts = [text.translate(str.maketrans('', '', string.punctuation)) for text in texts]\n",
        "# Remove stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "texts = [\" \".join([word for word in text.split() if word not in stop_words]) for text in texts]\n",
        "# Stem the words\n",
        "stemmer = PorterStemmer()\n",
        "texts = [\" \".join([stemmer.stem(word) for word in text.split()]) for text in texts]\n",
        "\n",
        "# Vectorize the text snippets\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "y = categories\n",
        "\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the categories for the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"The accuracy of the model is:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh5vrhU4-nHv",
        "outputId": "cba6dc3a-b838-4392-edc8-4d303263f6b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Number of text snippets: 4\n",
            "Number of categories: 5\n",
            "Text 1: I THINK EVERYONE HATES ME ON HERE lol\n",
            "Category 1: positive\n",
            "Length of texts: 4\n",
            "Text 2: soooooo wish i could, but im in school and myspace is completely blocked\n",
            "Category 2: negative\n",
            "Length of texts: 4\n",
            "Text 3: My bike was put on hold...should have known that.... argh total bummer\n",
            "Category 3: neutral\n",
            "Length of texts: 4\n",
            "Text 4: you guys didn`t say hi or answer my questions yesterday but nice songs\n",
            "Category 4: negative\n",
            "Length of texts: 4\n",
            "Length of categories: 5\n",
            "The accuracy of the model is: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}